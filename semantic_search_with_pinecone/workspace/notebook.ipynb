{"cells":[{"source":"# Semantic Search with Pinecone","metadata":{},"id":"8c8fde4c-9222-4265-b72b-8d7693520250","cell_type":"markdown"},{"source":"In this project you'll explore the world of vector databases and their use as the underlying data storage infrastructure for AI.\n\nThe project will introduce you to one of the most popular vector databases in industry, Pinecone. You'll  \n\n- Learn when and how semantic search can be used in products.\n- Learn why semantic search often performs better than traditional keyword search.\n- Learn how semantic search works, by exploring text about bees.\n- Use semantic search on the Stanford Question Answering Dataset to answer questions about Beyoncé, Chopin, and other culture.\n\n","metadata":{},"id":"3e302e1c-4c18-4c44-87fd-ba935c3a0853","cell_type":"markdown"},{"source":"### Maintenance note, May 2024\n\nSince this code-along was released, the Python packages for working with the Pinecone and OpenAI APIs have changed their syntax. The instructions, hints, and code have been updated to use the latest syntax, but the video has not been updated. Consequently, it is now slightly out of sync. Trust the workbook, not the video.","metadata":{},"id":"2e3e5078-91b6-4759-90b4-6dd311808871","cell_type":"markdown"},{"source":"### Terminology\n\nA _vector database_ is a type of database that only stores numeric vectors (unlike SQL databases that can store many different data types). By focusing on just one data format, vector databases can work quickly on 100s of billions of records.\n\n_Embedding_ is the process of converting data types like text to a _vector format_ suitable for storage in a vector database.\n\n_Vector search_ is when you find records in a vector database that are the best match to a query.\n\n_Semantic_ means the meaning of words.\n\n_Semantic search_ is when you do vector search on the meaning of text.","metadata":{},"id":"25726cb1-5915-4ca0-88b3-b46b7d8a6f48","cell_type":"markdown"},{"source":"### Uses of vector search\n\nVector search is an incredibly important technology that we all use _every single day_.\n\nVector search is how Amazon knows what you want to buy before even you do, it's how Netflix recommends TV shows and films, and it's how Google serves the most relevant results from the web at search time. \n\nWhen searching using natural language (as in the Google example), semantic search can often perform much better than keyword matching  (which is how traditional search works).\n\n![no-expansion](no-expansion.png)\n\n*Note, orangutans are apes, not monkeys — but not every query will be perfect from users.*","metadata":{},"id":"e2a078c8-5bb9-4c08-9d3b-7ee9063a7925","cell_type":"markdown"},{"source":"In this example, a traditional search that relies on keyword / term overlap will not perform well—despite the fact that this document is very relevant to the query. Here we need to search based on _meaning_, not keywords. It is in these natural language queries—ie queries structured in the way we, as human beings, think—that we are able to retrieve the relevant document to our query.\n\nUse-cases for this type of search are broad, but a few of the most common we find for semantic search include:\n\n* **Document search**: a favorite use-case for organizations, particularly those with poor internal document discovery. Enabling their staff to find the information they need quicker is a huge optimization for many organizations.\n* **Chatbot knowledge training**: another very popular use-case with the rise of AI chatbots is the ability to augment chatbots or **L**arge **L**anguage **M**odels (LLMs) with external data. We use semantic search to retrieval this data—this process is commonly referred to as **R**etrieval **A**ugmented **G**eneration (RAG).\n* **Language classification**: by placing many classified sequences into a vector DB we are able to more quickly classify new sentences by simply comparing their semantic similarity to existing entries in the vector DB.\n* **Agent/chatbot safety**: an increasingly popular use-case for semantic search is to use it in chatbot safety—it functions similarily to language classification but instead focuses on identifying malicious or unwanted inputs / outputs between users and chatbots.\n\nThese are a few example use-cases of semantic search, there are many more out there in the world which you will undoubtable encounter and be ready to recognize after completing this chapter and gaining the skills and knowledge to build your own semantic search apps.","metadata":{},"id":"3fd8cccb-7f1b-407b-945e-d75cc7301186","cell_type":"markdown"},{"source":"## Before you begin","metadata":{},"id":"8231d2c6-275e-4399-b7cd-84e112831d08","cell_type":"markdown"},{"source":"You'll need to get an [OpenAI API key](https://platform.openai.com/account/api-keys) and [Pinecone API key](https://app.pinecone.io). You can refer to *getting-started.ipynb* for steps on how to store these API keys in DataLab.","metadata":{},"id":"785d7fac-edb2-482f-be2b-c63dc2882103","cell_type":"markdown"},{"source":"## Task 0: Setup","metadata":{},"id":"a9274661-8d8c-4cc5-901e-5fc497866b89","cell_type":"markdown"},{"source":"Before we start building our chatbot, we need to install some Python libraries. Here's a brief overview of what each library does:\n\n- **openai**: This is the official OpenAI Python client. We'll use it to interact with the OpenAI API and generate embeddings for Pinecone.\n- **pinecone-client**: This is the official Pinecone Python client. We'll use it to interact with the Pinecone vector DB where we will store our semantic search database.\n- **datasets**: This library provides a vast array of datasets for machine learning. We'll use it to load our knowledge base for the chatbot.\n- **seaborn**: This is a popular plotting library. We'll use it for drawingheatmaps of similarity between sentences.","metadata":{},"id":"2cf847fd-f8f8-49f6-9b43-0eb098239072","cell_type":"markdown"},{"source":"### Instructions\n\nRun the following code to install the packages needed for this code-along.","metadata":{},"id":"6cecf97c-75b5-48af-bb56-b3938d5ab8d5","cell_type":"markdown"},{"source":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the datasets package, locked to version\n!pip install pinecone-client==4.0.0\n\n# Install the datasets package, locked to version 2.19.1\n!pip install datasets==2.19.1\n\n# Install the seaborn package, locked to version 0.13.2\n!pip install seaborn==0.13.2","metadata":{"executionCancelledAt":null,"executionTime":14359,"lastExecutedAt":1742955889863,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the datasets package, locked to version\n!pip install pinecone-client==4.0.0\n\n# Install the datasets package, locked to version 2.19.1\n!pip install datasets==2.19.1\n\n# Install the seaborn package, locked to version 0.13.2\n!pip install seaborn==0.13.2","outputsMetadata":{"0":{"height":616,"type":"stream"}},"lastExecutedByKernel":"0ab2ea3f-bc80-46c7-b065-084031b4f056","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"93ed93eb-f528-445b-9f68-77c18c1e5e20","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting openai==1.27\n  Downloading openai-1.27.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.8.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.27) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (0.27.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (2.7.1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.12.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.27) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (2.18.2)\nDownloading openai-1.27.0-py3-none-any.whl (314 kB)\nInstalling collected packages: openai\n\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed openai-1.27.0\nDefaulting to user installation because normal site-packages is not writeable\nCollecting pinecone-client==4.0.0\n  Downloading pinecone_client-4.0.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==4.0.0) (2025.1.31)\nRequirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==4.0.0) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==4.0.0) (4.12.2)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==4.0.0) (2.3.0)\nDownloading pinecone_client-4.0.0-py3-none-any.whl (214 kB)\nInstalling collected packages: pinecone-client\nSuccessfully installed pinecone-client-4.0.0\nDefaulting to user installation because normal site-packages is not writeable\nCollecting datasets==2.19.1\n  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (18.1.0)\nCollecting pyarrow-hotfix (from datasets==2.19.1)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (0.70.16)\nCollecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1)\n  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (0.28.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (6.0.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets==2.19.1) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.1) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.1) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.1) (1.16.0)\nDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\nDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, datasets\n\u001b[33m  WARNING: The script datasets-cli is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed datasets-2.19.1 fsspec-2024.3.1 pyarrow-hotfix-0.6\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.10/dist-packages (0.13.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.2) (1.26.4)\nRequirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.2) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.2) (3.10.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (23.2)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.16.0)\n"}]},{"source":"## Task 1: Semantic Similarity","metadata":{},"id":"92a9caca-70fd-4ac0-aa15-1bee55c456d3","cell_type":"markdown"},{"source":"We will start by understand what is actually happening under the hood of Pinecone. As mentioned, we're doing something called \"semantic similarity\". Semantic similarity is simply comparing the semantic meaning of two chunks of text.\n\nFor example, let's define a list of sentences and compare them based on their \"meaning\" as we (as humans) understand them.","metadata":{},"id":"b1fcd794-b29c-4010-8be0-651a452b2044","cell_type":"markdown"},{"source":"### Instructions\n\nRun this code to define a list containing text data. ","metadata":{},"id":"51f0bd9e-65be-4ccd-b66b-c55831c9c7be","cell_type":"markdown"},{"source":"sentences = [\n    \"the hive of bees protect their queen\",                         # 0\n    \"a beehive is an enclosed structure in which honey bees live\",  # 1\n    \"a condominium is an enclosed structure in which people live\",  # 2\n    \"the flying stinging insects guard the matriarch\"               # 3\n]","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1742955909980,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"sentences = [\n    \"the hive of bees protect their queen\",                         # 0\n    \"a beehive is an enclosed structure in which honey bees live\",  # 1\n    \"a condominium is an enclosed structure in which people live\",  # 2\n    \"the flying stinging insects guard the matriarch\"               # 3\n]","lastExecutedByKernel":"0ab2ea3f-bc80-46c7-b065-084031b4f056"},"id":"f81d6d0e-986b-49f4-94e1-7315a7f0bd67","cell_type":"code","execution_count":2,"outputs":[]},{"source":"### How similar are these sentences to humans?\n\nIt's clear to people that sentences 0 and 3 mean the same thing. Depending on the context we could view 1 and 2 as being similar in talking about where X lives, and 0, 1, and 3 are likewise similar in that they're talking about bees.\n\n### How similar are these sentences using keyword matching?\n\nIf we were to compare these using the more traditional approach of keyword matching we would very quickly run into problems. The sentences 1 and 2 might score well, but the other sentences have little-to-no overlap in keywords—so they would not be identified as similar.\n\n### Let's see how semantic search performs!\n\nIt is for these scenarios that we rely on semantic search. It works by teaching a language model to transform text into meaningful _vector embeddings_. We call them _meaningful_ because the language model actually learns to transform semantically similar sentences into a similar vector space (ie, in vector space, the embeddings are nearby).\n\nWe can try creating these embeddings using OpenAI's Ada 002 model like so:","metadata":{},"id":"dea6fc7d-20ea-4a6c-a0da-0b5bba034fa9","cell_type":"markdown"},{"source":"### Instructions\n\nEmbed the sentences using the Ada AI.\n\n- Import the OpenAI package.\n- Set the model to Ada version 002, `\"text-embedding-ada-002\"`. Assign to `model`.\n- Define an OpenAI client model. Assign to `client`.\n- Send `sentences` to OpenAI API to create embeddings. Assign to `res`.","metadata":{},"id":"1642de3e-a643-4285-8245-fe3a516c6561","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nDefine the client model with `openai.OpenAI()`. No arguments are needed here.\n    \n---\n    \nCreate embeddings for the text with `client.embeddings.create()`, passing the text to the `input` argument and the name of the model to use to `model`.\n    \n```py\nresponse = client.embeddings.create(input=text, model=model)\n```\n\n</p>\n</details>","metadata":{},"id":"d231ef09-dfe7-4aff-8aa5-34a63339aa22","cell_type":"markdown"},{"source":"# Import the openai package\n\n\n# Set the model to Ada version 002. Assign to model.\n\n\n# Define an OpenAI client model. Assign to client.\n\n\n# Send sentences to OpenAI API to create embeddings. Assign to res.\n","metadata":{"executionCancelledAt":null,"executionTime":261,"lastExecutedAt":1715624771377,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the openai package\nimport openai\n\n# Set the model to Ada version 002. Assign to model.\nmodel = \"text-embedding-ada-002\"\n\n# Define an OpenAI client model. Assign to client.\nclient = openai.OpenAI()\n\n# Send sentences to OpenAI API to create embeddings. Assign to res.\nres = client.embeddings.create(input=sentences, model=model)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"04f8ef03-b380-46c2-801c-6f9bfb49e84c","cell_type":"code","execution_count":4,"outputs":[]},{"source":"### Instructions\n\n- Pull out the embeddings from the API response into list. Assign to `embeds`.\n- _Look at the statistics about the embeddings. What do you think those numbers mean?_","metadata":{},"id":"8330f689-8668-40e9-af54-2976d3e6048b","cell_type":"markdown"},{"source":"# Pull out the embeddings from the API response into list. Assign to embeds.\n\n\n# Show some stats about the size of the results\nprint(\"There are this many embeddings: \", len(embeds))\nprint(\"Each embedding is a vector containing this many numbers: \", len(embeds[0]))","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1715624896629,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Pull out the embeddings from the API response into list. Assign to embeds.\nembeds = [r.embedding for r in res.data]\n\n# Show some stats about the size of the results\nprint(\"There are this many embeddings: \", len(embeds))\nprint(\"Each embedding is a vector containing this many numbers: \", len(embeds[0]))","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"a428cea3-cf73-4355-bab6-abe1e645eb3a","cell_type":"code","execution_count":7,"outputs":[]},{"source":"We have `4` embeddings (one for each of our four sentences). Ada 002 also outputs an embedding dimensionality of `1536`. \n\nThat is, embedding has converted each sentence (regardless of its length) to a vector of 1536 floating point numbers.","metadata":{},"id":"34652246-b6d8-4c8f-8e8f-f2530e29acfb","cell_type":"markdown"},{"source":"# Is each embedding the same size?\n","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1715624899278,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Is each embedding the same size?\nlen(embeds[0]), len(embeds[1]), len(embeds[2]), len(embeds[3])","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"850470c0-b019-40da-8af7-418afb6ad76e","cell_type":"code","execution_count":8,"outputs":[]},{"source":"### Measuring similarity\n\nNow that we have numeric vectors instead of text, we can calculate how similar the sentences are to each other. There are several common measures for calculating how similar two numeric vectors are, including _dot product_ and _cosine similarity_.\n\nHere, we'll use the _dot product_. If you imagine the numeric vectors as arrows pointing in different directions in space, then the dot product measures how closely those arrows point in the same direction.\n\nFor each pair of sentences, you get a score between `-1` and `1`. A score of one mean that the sentences have identical meaning. Lower scores indicate less similarity, and in practice, for two well-formed sentences in English, the dot product similarity seldom drops much below `0.7`.","metadata":{},"id":"07014391-ce2a-43b6-86bc-aa25bbbc6957","cell_type":"markdown"},{"source":"### Instructions\n\nCalculate the dot product of the embedded sentences.\n\n- From `numpy`, import `dot` and `array`.\n- Convert `embeds` to an array. Assign to `embeds_arr`.\n- Get the dot product of `embeds_arr` and its transpose. Assign to `dot_product`.\n- Print the result.","metadata":{},"id":"bc672e26-65bf-45b8-a01a-35e6a5d62f93","cell_type":"markdown"},{"source":"# From the numpy package, import dot, array\n\n\n# Convert the embeddings to a numpy array\n\n\n# What shape does the array have?\n","metadata":{"executionCancelledAt":null,"executionTime":13,"lastExecutedAt":1715624902608,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# From the numpy package, import dot, array\nfrom numpy import dot, array\n\n# Convert the embeddings to a numpy array\nembeds_arr = array(embeds)\n\n# What shape does the array have?\nembeds_arr.shape","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"4c4d7ad2-5f0d-48bd-867f-5e29fbf5741f","cell_type":"code","execution_count":9,"outputs":[]},{"source":"# Calculate the dot product of the embedding array with its transpose\n\n\n# What shape does the dot product have?\n","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1715624905348,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Calculate the dot product of the embedding array with its transpose\ndot_prod = dot(embeds_arr, embeds_arr.T)\n\n# What shape does the dot product have?\ndot_prod.shape","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"43851832-8417-469d-9885-edc65629a15b","cell_type":"code","execution_count":10,"outputs":[]},{"source":"# Print the dot product array\n","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1715624908134,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Print the dot product array\ndot_prod","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"0ca37358-7f15-42f2-be67-10df4f064944","cell_type":"code","execution_count":11,"outputs":[]},{"source":"### Visualizing similarity\n\nArray of numbers are tedious to read, but can visualize these similarity values with a heatmap. For each value in the dot product, we get a colored cell.\n\nEvery sentence will be perfectly similar to itself, so the cells on the diagonal will have a score of one (and in the default Seaborn color scheme have a pale red color).\n\nSentences that are less alike will have a lower score and a darker colored cell.","metadata":{},"id":"ab33f0be-0297-4b52-a2dc-92dae64fdf3b","cell_type":"markdown"},{"source":"### Instructions\n\nDraw a heatmap of the dot product array to visualize how similar each sentence is.\n\n- Import `seaborn` with the alias `sns`.\n- Draw a heatmap of `dot_product` with annotations.","metadata":{},"id":"b6bbd7f4-102a-4686-842d-270a914b86cb","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nDraw a heatmap with `sns.heatmap()`, passing the array. Include annotations using `annot=true`.\n\n</p>\n</details>","metadata":{},"id":"0b71cf5c-fb0c-4af7-a179-0927a039a749","cell_type":"markdown"},{"source":"# Import seaborn using the standard alias\n\n\n# Plot a heatmap of the dot product, including annotations\n","metadata":{"executionCancelledAt":null,"executionTime":431,"lastExecutedAt":1715625271896,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import seaborn using the standard alias\nimport seaborn as sns\n\n# Plot a heatmap of the dot product, including annotations\nsns.heatmap(dot_prod, annot=True)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"8ae3d4cd-25a0-478a-8b49-56badfeaaacb","cell_type":"code","execution_count":26,"outputs":[]},{"source":"### How similar are the sentences?\n\nFrom this we can see that the most similar pairs are:\n\n| Pair | Similarity | A | B |\n| ---- | ---------- | --- | --- |\n| 0-3  | 0.89       | \"the hive of bees protect their queen\" | \"the flying stinging insects guard the matriarch\" |\n| 0-1  | 0.88       | \"the hive of bees protect their queen\" | \"a beehive is an enclosed structure in which honey bees live\" |\n| 1-2  | 0.85       | \"a beehive is an enclosed structure in which honey bees live\" | \"a condominium is an enclosed structure in which people live\" |\n| 1-3  | 0.81       | \"a beehive is an enclosed structure in which honey bees live\" | \"the flying stinging insects guard the matriarch\" |\n| 0-2  | 0.76       | \"the hive of bees protect their queen\" | \"a condominium is an enclosed structure in which people live\" |\n| 2-3  | 0.74       | \"a condominium is an enclosed structure in which people live\" | \"the flying stinging insects guard the matriarch\" |\n\nThis ordering of semantic similarity seems to align well with how most people would order them in terms of similarity in meaning—and it is for that, that these embedding models are optimized.","metadata":{},"id":"061c7558-5cbd-4408-9f79-d08c5dcf95b3","cell_type":"markdown"},{"source":"## Task 2: Importing the Dataset\n\nWe typically would not do semantic search for comparing just four sentences. Instead, it is done with thousands, millions, or even billions of records—Google is a great example of a partly semantic search done at large scales.\n\nWe'll perform semantic serach on the **S**tanford **Qu**estion **A**nswering **D**ataset v2 (SQuAD v2), the second version of a popular question-answering dataset. It contains _contexts_ which are simply paragraphs that contain information that can help a language model answer the question provided in the _question_ column.\n\nIn this task, you will:\n\n* Download the [`squad_v2`](https://huggingface.co/datasets/squad_v2) dataset using Hugging Face Datasets.\n* Take a look at the dataset structure, paying attention to the **context** and **question** columns.\n* Deduplicate the **context** column to return a list of paragraphs that we will later search through.","metadata":{},"id":"01a1e00a-3b40-4943-b2b6-afe104ac8412","cell_type":"markdown"},{"source":"### Instructions\n\nDownload and print the `squad_v2` dataset.\n\n- From `datasets`, import `load_dataset`\n- Load the `squad_v2` dataset, just getting the training split. Assign to `data`.\n- Print the dataset object.","metadata":{},"id":"e90eb2da-190a-4dd9-a2b0-eb26d1afaa96","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nLoad the dataset with `load_dataset()`. Set `split=\"train\"` to get the training set.\n\n</p>\n</details>","metadata":{},"id":"5eda1f8d-dc3d-46a6-b06b-47f599e72eec","cell_type":"markdown"},{"source":"# From the datasets package, import load_dataset\n\n\n# Load the squad_v2 dataset, getting the training split. Assign to data.\n\n\n# Print the dataset\n","metadata":{"executionCancelledAt":null,"executionTime":3205,"lastExecutedAt":1715625289923,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# From the datasets package, import load_dataset\nfrom datasets import load_dataset\n\n# Load the squad_v2 dataset, getting the training split. Assign to data.\ndata = load_dataset(\"squad_v2\", split=\"train\")\n\n# Print the dataset\ndata","outputsMetadata":{"3":{"height":76,"type":"stream"},"10":{"height":76,"type":"stream"}},"lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"a2fb915f-3623-4bbb-a211-ebed96615b10","cell_type":"code","execution_count":27,"outputs":[]},{"source":"### Instructions\n\nPrint and read some records from the squad dataset.\n\n- Print several records of `data`, one at at time.\n- *Read the contents. What is the structure of each record? What are the contents about?*","metadata":{},"id":"12488077-3805-4ba3-a2f1-64385f1ee438","cell_type":"markdown"},{"source":"# Print an element of data\n","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1715625295099,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Print an element of data\ndata[0]","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"b5bbd68a-a7c2-4dcd-b119-3d7abf3adeec","cell_type":"code","execution_count":28,"outputs":[]},{"source":"# Print another element of data\n","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1715625298273,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Print another element of data\ndata[1]","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"021c24b9-7c40-4374-b1f1-11a95b1e9b47","cell_type":"code","execution_count":29,"outputs":[]},{"source":"# Print yet another element of data\n","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1715625300808,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Print yet another element of data\ndata[500]","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"14e2443f-33c6-4c07-8996-b73a1ff466c0","cell_type":"code","execution_count":30,"outputs":[]},{"source":"# Print one more element of data, for good luck\n","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1715625303006,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Print one more element of data, for good luck\ndata[1500]","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"c3d7b62e-2cf5-48aa-a3cf-8184256348db","cell_type":"code","execution_count":31,"outputs":[]},{"source":"As there are many questions for each context, we see plenty of duplication in the _context_ column. Our next task is to deduplicate those records to give us a deduped `contexts` list.","metadata":{},"id":"136f697e-acc6-401c-97e0-1ba0404af7f2","cell_type":"markdown"},{"source":"### Instructions\n\nRemove duplicates of context values from the dataset.\n\n- Deduplicate the `context` element of `data` by converting to a set and back to a list. Assign to `contexts`.\n- Print the length of `contexts`.","metadata":{},"id":"ebc90239-de4f-494b-86d3-20228500d086","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nConverting a list to a set with `set()` removes duplicates. Use `list()` to convert the set back to a list.\n\n</p>\n</details>","metadata":{},"id":"ca0fed4e-c2f9-46d6-8e4e-97ceaf86a573","cell_type":"markdown"},{"source":"# Deduplicate the context element of data. Assign to contexts.\n\n\n# How many elements are there in contexts?\n","metadata":{"executionCancelledAt":null,"executionTime":251,"lastExecutedAt":1715625306530,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Deduplicate the context element of data. Assign to contexts.\ncontexts = list(set(data[\"context\"]))\n\n# How many elements are there in contexts?\nlen(contexts)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"0b610297-8b6b-4f74-80a7-518a08ca0c2c","cell_type":"code","execution_count":32,"outputs":[]},{"source":"## Task 3: Creating a Vector Index\n\n","metadata":{},"id":"f11ab789-e626-49a3-8699-d8222e89f6e5","cell_type":"markdown"},{"source":"Storing the embeddings in a NumPy array is not very permanent, or useful for sharing with other people. The embeddings need to be stored in a vector database, in this case Pinecone.\n\nThis task involves some setup steps to get the embeddings into Pinecone.\n","metadata":{},"id":"f76fd76e-242d-404a-b48b-a407ad44f328","cell_type":"markdown"},{"source":"### Terminology \n\nIn Pinecone there are three levels of containers.\n\nAt the highest level is the _vector database_ itself. This is the equivalent to a SQL DB.\n\nWithin the SQL DB we have tables which contain our data; with Pinecone we have _vector indexes_.\n\nOne more layer that we can optionally use is _namespaces_. A namespace is a partition within a vector index. Every namespace is fully separated from other namespaces, and because of this they are often use to support multi-tenancy. So, if your product served multiple business, you could store business A's data in namespace \"a\", and business B's data in namespace \"b\" to ensure they are always separated.\n\nWe will not dive into namespaces here, but they are a useful concept to be aware of when building with Pinecone.","metadata":{},"id":"2996f94d-6240-448c-b6c7-e14c118105f9","cell_type":"markdown"},{"source":"To create our first vector index we first need to initialize our connection to Pinecone.","metadata":{},"id":"4200061e-46d1-4032-8f3c-bb1d816814a7","cell_type":"markdown"},{"source":"### Instructions\n\nInitialize Pinecone, getting setup details from DataLab environment variables.\n\n- Import the `os` package.\n- Import the `pinecone` package.\n- Set the pinecone api key from the environment variable. Assign to `api_key`.\n- Initialize Pinecone using the API key. Assign to `pc`.","metadata":{},"id":"cae79900-ea2d-418b-8a79-9d0aba78b3e6","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nThe Pinecone environment variable is usually called `PINECONE_API_KEY`, but check what you called it!\n    \n---\n    \nTo initialize Pinecone, call `pinecone.Pinecone()`, setting `api_key` to the API key.\n\n</p>\n</details>","metadata":{},"id":"4f9c29ce-e78b-4a64-8e05-d99d9a2b6b03","cell_type":"markdown"},{"source":"# Import the os package\n\n\n# Import the pinecone package\n\n\n# Set the pinecone api key from the environment variable. Assign to api_key.\n\n\n# Initialize Pinecone using the API key. Assign to pc.\n","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1715625385960,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the os package\nimport os\n\n# Import the pinecone package\nimport pinecone\n\n# Set the pinecone api key from the environment variable. Assign to api_key.\napi_key = os.environ[\"PINECONE_API_KEY\"]\n\n# Initialize Pinecone using the API key. Assign to pc.\npc = pinecone.Pinecone(api_key=api_key)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"d980782a-78a1-4eb5-b83c-43fbe830d750","cell_type":"code","execution_count":35,"outputs":[]},{"source":"Now we can create our index. There are a few parameters we must include. Those are:\n\n- `index_name`: this can be anything you want, it is simply the name of the index—so use something informative!\n- `dimension`: this is the expected dimensionality of the vectors in the index. We saw earlier that Ada 002 encodes into 1536-dimensional vectors, so we use that same `1536` number here.\n- `metric`: this is the similarity metric we will use to compare vectors. For Ada 002 we can use `dot_product` (as we did above) or `cosine`. Other embedding may require us to use `euclidean` but this is less common. \n- `spec`: whether to use Pinecone Serverless (newer, faster and cheaper) or Pod (legacy) architecture, and the architecture details.","metadata":{},"id":"d36a02f0-98e0-4e03-94cc-cf1a5ba0f5d4","cell_type":"markdown"},{"source":"### Instructions\n\nCreate a vector index and connect to it.\n\n- Import `time`.\n- Give the index a meaningful name, such as `\"squad-search\"`. Assign to `index_name`.\n- Check if the index already exists. (It shouldn't on the first run.)\n    - If the index does not exist then create it.\n    - Wait for the index to initialize. If the index status isn't \"ready\" then sleep for a couple of seconds.","metadata":{},"id":"1350f13a-d628-4699-b0ff-b4fbbab05438","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nGet the list of available indexes with `pc.list_indexes()`. The code pattern to get all available index names is as follows.\n    \n```py\n[idx.name for idx in pc.list_indexes().indexes]\n```\n \n    \n---\n    \nCreate an index with `pc.create_index()`, passing the index name, and setting the dimension, metric, and spec. In theory, you can specify where in the cloud Pinecone runs. Currently, Pinecone Serverless only runs in AWS us-west-2. The code pattern to create an index is as follows.\n    \n```py\npc.create_index(\n        index_name,\n        dimension=n_dims,\n        metric=\"cosine|dotproduct|euclidean\",\n        spec=pinecone.ServerlessSpec(\n            cloud=\"aws\",\n            region=\"us-west-2\"\n        )\n    )\n```\n \n    \n---\n    \nGet the index details with `pc.describe_index(index_name)`. The code pattern to check that the index is ready is as follows.\n    \n```py\npc.describe_index(index_name).status[\"ready\"]\n```\n\n---\n    \nThe code pattern for sleeping until a condition is met is as follows.\n    \n```py\nwhile not condition\n    time.sleep(n)\n```\n    \n</p>\n</details>","metadata":{},"id":"7ece2fab-91be-438e-a3b4-d61dcb51799c","cell_type":"markdown"},{"source":"# Import the time package\n\n\n# Name the index. Assign to index_name.\n\n\n# List the names of available indexes. Assign to existing_index_names.\n\n\n# Check if index_name is not in the list of available indexes\n\n    # Create the index with index_name, a dimension of 1536, and the metric \"cosine\"\n    \n    # If the index status is not ready, sleep for 2 seconds\n    ","metadata":{"executionCancelledAt":null,"executionTime":5505,"lastExecutedAt":1715625496470,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the time package\nimport time\n\n# Name the index. Assign to index_name.\nindex_name = \"squad-search\"\n\n# Check if index_name is not in the list of available indexes\nif index_name not in pc.list_indexes():\n    # Create the index with index_name, a dimension of 1536, and the metric \"cosine\"\n    pc.create_index(\n        index_name,\n        dimension=1536,\n        metric=\"cosine\",\n        spec=pinecone.ServerlessSpec(\n            cloud=\"aws\",\n            region=\"us-east-1\"\n        )\n    )\n    # If the index status is not ready, sleep for 2 seconds\n    while not pc.describe_index(index_name).status[\"ready\"]:\n        time.sleep(2)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"ef338ced-97f6-47ec-89d6-90e373984574","cell_type":"code","execution_count":38,"outputs":[]},{"source":"### Instructions\n\n- Connect to the index. Assign to `index`.","metadata":{},"id":"fe75da1a-6530-40bb-b529-ee20013de2fe","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nConnect to an index by name using `pc.Index()`, passing the name.\n\n</p>\n</details>","metadata":{},"id":"6fa9d215-576b-457a-83ec-77d92e2e17e3","cell_type":"markdown"},{"source":"# Connect to the index using its name. Assign to index.\n","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1715625500799,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Connect to the index using its name. Assign to index.\nindex = pc.Index(index_name)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"3e9feb15-957b-41a9-93da-d31732189f3c","cell_type":"code","execution_count":39,"outputs":[]},{"source":"### Instructions\n\n- Get statistics describing the index.","metadata":{},"id":"27d5401f-71a3-4a54-bca4-9862dbd2f8e9","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nGet statistics for an index with `index.describe_index_stats()`.\n\n</p>\n</details>","metadata":{},"id":"ad7c26c1-1872-4418-9de0-306419191dfe","cell_type":"markdown"},{"source":"# Get statistics describing the index\n","metadata":{"executionCancelledAt":null,"executionTime":106,"lastExecutedAt":1715625503957,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Get statistics describing the index\nindex.describe_index_stats()","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"ec3ad477-023e-4a3a-8425-735a92c191c0","cell_type":"code","execution_count":40,"outputs":[]},{"source":"Our index has now been created and we can see that the vector count is currently `0`, as we haven't added anything to it yet.","metadata":{},"id":"14da95d2-6058-4cab-b303-b9d8659fcf3a","cell_type":"markdown"},{"source":"## Task 4: Indexing our Data","metadata":{},"id":"b6f3ad04-fcd5-45fd-bf6c-a51c26fd00b0","cell_type":"markdown"},{"source":"Now that we have our embedding model (Ada 002), dataset, and vector index, we can begin embedding our data and added it all to the index.\n\nWe will do this in batches of `100` to avoid overloading the OpenAI or Pinecone APIs (or causing out of memory errors on our own system).","metadata":{},"id":"878fa83a-d5e1-481c-813b-44dcc8b39cd7","cell_type":"markdown"},{"source":"### Instructions\n\nSplit the dataset into batches and add it to the vector index.\n\n- From `tqdm`, import `tqdm` (a progress bar).\n- Set the batch size to 100. Assign to `batch_size`.\n- Define an OpenAI client model. Assign to `client`.\n- Loop from 0 to the length of contexts by batch size, adding a progress bar.\n    - Find the end of the batch. Assign to `i_end`.\n    - Get the contexts for the batch to encode. Assign to `context_batch`.\n    - Convert the numbers from `i` to `i_end` to strings to use as IDs for the batch. Assign to `ids_batch`.\n    - Create the embeddings for the batch contexts. Assign to `res`.\n    - Pull out the embeddings for each record in the response data. Assign to `embeds`.\n    - Add contexts to metadata for easy retrieval later. Assign to `metadata`.\n    - Combine IDs, embeddings, and metadata as list of tuples. Assign to `to_upsert`.\n    - Upsert to Pinecone.","metadata":{},"id":"63801da1-f02d-4282-9182-bae8946f6815","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nThe code pattern to create a progress bar is as follows.\n    \n```py\nfor i in tqdm(range(start, stop, step))\n    # do something\n```\n\n---\n\nThe position of the end of the batch is either the current position, `i`, plus the batch size or the length of the contexts, whichever is smaller.\n\n---\n\nYou can convert numbers to strings using `str()` and a list comprehension.\n    \n```py\n[str(i) for i in range(start, stop)]\n```\n\n---\n\nCreate the embeddings using `client.embeddings.create()`, where client is the OpenAI client model you used previously.\n\n---\n\nIf `res` is a response from the embeddings call, then `res.data` contains the data. The embeddings are contained in the `.embedding` element of that data. Use a list comprehension to extract them.\n    \n```py\n[d.embedding for d in res.data]\n```\n\n---\n\nMetadata should take the form `{\"context\": record}` for each record in the context batch. Use a list comprehension to get them all.\n\n---\n\nUse `zip()` to combine several lists as a list of tuples.\n\n---\n\nTo upsert the list of tuples call `index.upsert()`, setting `vectors=to_upsert`.\n\n</p>\n</details>","metadata":{},"id":"930ce88d-3836-4b62-baf9-bdfc96c2f425","cell_type":"markdown"},{"source":"# From the tqdm package, import tqdm\n\n\n# Set the batch size to 100. Assign to batch_size.\n\n\n# Define an OpenAI client model. Assign to client\n\n\n# Loop from 0 to the number of contexts in steps of batch_size. Create a progress bar.\n\n    # Find the end of the batch. Assign to i_end.\n    \n    \n    # Get the contexts for the batch to encode. Assign to context_batch.\n    \n    \n    # Get the IDs for the batch. Assign to ids_batch.\n    \n    \n    # Create the embeddings for the batch contexts. Assign to res.\n    \n    \n    # Pull out the embeddings for each record in the response data. Assign to embeds.\n    \n    \n    # Add contexts to metadata for easy retrieval later. Assign to metadata.\n    \n    \n    # Combine IDs, embeddings, and metadata as list of tuples. Assign to to_upsert.\n    \n    \n    # Upsert to Pinecone\n    ","metadata":{"executionCancelledAt":null,"executionTime":292671,"lastExecutedAt":1715625822855,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# From the tqdm package, import tqdm\nfrom tqdm import tqdm\n\n# Set the batch size to 100. Assign to batch_size.\nbatch_size = 100\n\n# Define an OpenAI client model. Assign to client\nclient = openai.OpenAI()\n\n# Loop from 0 to the number of contexts in steps of batch_size. Create a progress bar.\nfor i in tqdm(range(0, len(contexts), batch_size)):\n    # Find the end of the batch. Assign to i_end.\n    i_end = min(i+batch_size, len(contexts))\n    \n    # Get the contexts for the batch to encode. Assign to context_batch.\n    context_batch = contexts[i:i_end]\n    \n    # Get the IDs for the batch. Assign to ids_batch.\n    ids_batch = [str(x) for x in range(i, i_end)]\n    \n    # Create the embeddings for the batch contexts. Assign to res.\n    res = client.embeddings.create(input=context_batch, model=model)\n    \n    # Pull out the embeddings for each record in the response data. Assign to embeds.\n    embeds = [d.embedding for d in res.data]\n    \n    # Add contexts to metadata for easy retrieval later. Assign to metadata.\n    metadata = [{\"context\": record} for record in context_batch]\n    \n    # Combine IDs, embeddings, and metadata as list of tuples. Assign to to_upsert.\n    to_upsert = zip(ids_batch, embeds, metadata)\n    \n    # Upsert to Pinecone\n    index.upsert(vectors=to_upsert)","outputsMetadata":{"0":{"height":38,"type":"stream"}},"lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"937ffa6c-0f54-404f-a2f2-97df1d860b17","cell_type":"code","execution_count":42,"outputs":[]},{"source":"Now we can check our index size and we should see it has been populated with records (as seen via the vector count):","metadata":{},"id":"fd8f72e9-417d-4521-8ce9-9d02fe24b2c2","cell_type":"markdown"},{"source":"### Instructions\n\nCheck on updates to the vector index now that it contains the squad dataset.\n\n- View the index stats again.\n- *What has changed since you last looked?*","metadata":{},"id":"3f495545-3ab9-4eb3-9fb8-89f084c84415","cell_type":"markdown"},{"source":"# Get statistics to describe the index again. What has changed?\n","metadata":{"executionCancelledAt":null,"executionTime":119,"lastExecutedAt":1715626203686,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Get statistics to describe the index again. What has changed?\nindex.describe_index_stats()","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"fd87af30-b8a6-4ac0-8bc8-fd2e3916dc1e","cell_type":"code","execution_count":43,"outputs":[]},{"source":"## Task 5: Semantic Search","metadata":{},"id":"b1732087-e9a3-4d69-8d4d-deeaa6dc1317","cell_type":"markdown"},{"source":"We've now indexed our data, meaning we're ready for semantic search!\n\nThis just means that we start with a query, that is, a question to ask. Then by using similarity, we find the three questions in the squad dataset with the nearest meaning to the one we asked.\n\n### What's the search workflow?\n\n1. The query is text, so first it needs to be embedded. \n2. The embedded query can be searched using Pinecone's `index.query()`. To return the metadata in our response we'll also need to set `include_metadata=True`.\n\nLet's create the query and embed it with Ada 002.","metadata":{},"id":"1f9063bd-0abe-452b-89b0-f8bd3fea2e2b","cell_type":"markdown"},{"source":"### Instructions\n\nThink of a question, then embed it.\n\n- Specify a question, `\"What three composers did Chopin take inspiration from?\"`. Assign to `query`.\n- Create the embedding for the query. Assign to `res`.\n- Pull out the query vector from the response. Assign to `xq`.","metadata":{},"id":"5c185526-0521-4967-a7a8-2d51b418046e","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nWhen creating the embeddings, `client.embeddings.create()` expects a list, so wrap `query` in square brackets.\n\n---\n\nIf the response from the embeddings API is `res`, then the query vector is stored in `res.data[0].embedding`.\n\n</p>\n</details>","metadata":{},"id":"30a6c65e-c421-4211-b707-f5f1e4e5baa4","cell_type":"markdown"},{"source":"# Define a query\nquery = \"What three composers did Chopin take inspiration from?\"\n\n# Create embeddings for the query\n","metadata":{"executionCancelledAt":null,"executionTime":157,"lastExecutedAt":1715626221872,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a query\nquery = \"What three composers did Chopin take inspiration from?\"\n\n# Create embeddings for the query\nres = client.embeddings.create(input=[query], model=model)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"fb29ee9b-4341-4e6d-82a7-0538765edaf7","cell_type":"code","execution_count":45,"outputs":[]},{"source":"# Pull out the query vector from the response. Assign to xq.\n","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1715626232196,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Pull out the query vector from the response. Assign to xq.\nxq = res.data[0].embedding","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"72cf0ac8-9843-45d5-9d03-8e699d12da12","cell_type":"code","execution_count":46,"outputs":[]},{"source":"# Sanity check: how many elements are in xq?\n","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1715626234343,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Sanity check: how many elements are in xq?\nlen(xq)","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"26bebeb6-5660-4b89-9552-a7a7d504d12c","cell_type":"code","execution_count":47,"outputs":[]},{"source":"Now we query Pinecone.","metadata":{},"id":"e233ee37-fe40-49ea-a698-4f858b730bc4","cell_type":"markdown"},{"source":"### Instructions\n\nQuery Pinecone for matches to the embedded question.\n\n- Query the index for the top 3 matches to `xq`, including metadata in the results. Assign to `res`.\n- Print the results.","metadata":{},"id":"33fc7480-d137-40e0-9033-7bfd251f63a4","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nTo query an index, call `index.query()`, setting `vector` to the embedding to query against, `top_k` to the number of matches to return, and `include_metadata` to `True`.\n\n</p>\n</details>","metadata":{},"id":"89e87bfb-10da-429d-91af-9026377766c8","cell_type":"markdown"},{"source":"# Query the index for the top 3 matches to xq, including metadata. Assign to res.\n\n\n# Print the results\n","metadata":{"executionCancelledAt":null,"executionTime":1027,"lastExecutedAt":1715626302866,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Query the index for the top 3 matches to xq, including metadata. Assign to res.\nres = index.query(vector=xq, top_k=3, include_metadata=True)\n\n# Print the results\nres","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"51d5bd5e-47e5-46f0-9727-0f5fc211a8f9","cell_type":"code","execution_count":49,"outputs":[]},{"source":"That's a big response, let's clean it up and also wrap the search logic into a single `search` function.","metadata":{},"id":"f6b4cc25-63a3-416d-9ae1-54aa40dd01f7","cell_type":"markdown"},{"source":"### Instructions\n\n- Run this code to define a convenience function for semantic search with prettier output.","metadata":{},"id":"2ffd248c-8dce-43f1-9ffc-d253b9619e47","cell_type":"markdown"},{"source":"# Run this to define the search() function\ndef search(query):\n    client = openai.OpenAI()\n    res = client.embeddings.create(input=[query], model=model)\n    xq = res.data[0].embedding\n    res = index.query(vector=xq, top_k=3, include_metadata=True)\n    # format\n    xc = []\n    for match in res.matches:\n        context = match.metadata[\"context\"]\n        score = match.score\n        xc.append(f\"[{round(score, 2)}]: {context}\")\n    return xc","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1715626548763,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this to define the search() function\ndef search(query):\n    client = openai.OpenAI()\n    res = client.embeddings.create(input=[query], model=model)\n    xq = res.data[0].embedding\n    res = index.query(vector=xq, top_k=3, include_metadata=True)\n    # format\n    xc = []\n    for match in res.matches:\n        context = match.metadata[\"context\"]\n        score = match.score\n        xc.append(f\"[{round(score, 2)}]: {context}\")\n    return xc","lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"a0fd26a8-ba8d-44ba-9d8e-a3ef4f18f915","cell_type":"code","execution_count":62,"outputs":[]},{"source":"### Instructions\n\nPrint each result of searching for the query.","metadata":{},"id":"56334eee-4c2e-421b-991e-e1ab87461d51","cell_type":"markdown"},{"source":"# For each result of searching for the query, print it\n","metadata":{"executionCancelledAt":null,"executionTime":391,"lastExecutedAt":1715626557089,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# For each result of searching for the query, print it\nfor result in search(query):\n    print(result)","outputsMetadata":{"0":{"height":416,"type":"stream"}},"lastExecutedByKernel":"a2474d7a-604e-433e-8ce1-a795afd2d79b"},"id":"7e96d2a1-1694-47eb-a5a9-b8e89606ccd8","cell_type":"code","execution_count":63,"outputs":[]},{"source":"### So who did influence Chopin?\n\nThe top result directly answers the question of who influenced Chopin. It seems there are a lot of influences, depending on what aspect of his music and what time period of his work you consider. Beethoven, Haydn, Mozart, Clementi, Hummel, Bach, Moscheles, and Kalkbrenner are mentioned, as well as Polish folk music and Italian opera.\n\nThe second and third results talk about people who were influenced by Chopin. This is closely related in meaning to the question, but not quite what was asked.","metadata":{},"id":"0a166615-acf3-4859-be1c-340d5e91c8ca","cell_type":"markdown"},{"source":"## Summary\n\nIn this code-along, you've seen \n\n- some examples of when vector search and semantic search can be used.\n- why semantic search can have better performance than keyword search.\n- how to embed text with the Ada AI.\n- how to initialize a Pinecone database and create a vector index.\n- how to add text data to a Pinecone vector index.\n- how to query a vector index to find close matches.","metadata":{},"id":"040d2638-00b6-4237-828f-5b48aac16b00","cell_type":"markdown"},{"source":"## Keep Going!\n\nThe squad dataset contains a lot of question and answer pairs, so there are many more things you can search for.\n\nRepeat the steps in Task 5, trying different values for the query.\n\nHere are a few ideas for the query:\n\n* `\"What years did Ogedei Khan rule?\"`\n* `\"Which model of iPod combined the headphone jack and data port?\"`\n* `\"Who resurrects Zelda after the fight with Ganondorf?\"`\n\nMake sure to look at the output from each search result, and see how well the results answer the query.","metadata":{},"id":"722d42e9-04d7-496d-9db2-d2d5825cad6b","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}